{
    "model_statistics": {
        "total_parameters": 0,
        "num_layers": 0,
        "model_size_mb": 0.0,
        "model_code": "def forward(self,\n    input: Tensor) -> Tensor:\n  prepack_folding__jit_pass_packed_weight_0 = getattr(self, \"prepack_folding._jit_pass_packed_weight_0\")\n  _0 = ops.prepacked.conv2d_clamp_run(input, prepack_folding__jit_pass_packed_weight_0)\n  prepack_folding__jit_pass_packed_weight_1 = getattr(self, \"prepack_folding._jit_pass_packed_weight_1\")\n  _1 = ops.prepacked.conv2d_clamp_run(_0, prepack_folding__jit_pass_packed_weight_1)\n  prepack_folding__jit_pass_packed_weight_2 = getattr(self, \"prepack_folding._jit_pass_packed_weight_2\")\n  _2 = ops.prepacked.conv2d_clamp_run(_1, prepack_folding__jit_pass_packed_weight_2)\n  _3 = torch.size(_2, 0)\n  _4 = torch.size(_2, 1)\n  c = ops.prim.NumToTensor(_4)\n  _5 = torch.size(_2, 2)\n  h = ops.prim.NumToTensor(_5)\n  _6 = torch.size(_2, 3)\n  _7 = int(torch.mul(c, CONSTANTS.c0))\n  _8 = int(torch.floor_divide(h, CONSTANTS.c0))\n  input0 = torch.view(_2, [_3, _7, _8, _6])\n  x = torch.batch_norm(input0, CONSTANTS.c1, CONSTANTS.c2, CONSTANTS.c3, CONSTANTS.c4, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input1 = torch.view(x, [_3, _4, _5, _6])\n  input2 = torch.adaptive_avg_pool2d(input1, [1, 201])\n  prepack_folding__jit_pass_packed_weight_3 = getattr(self, \"prepack_folding._jit_pass_packed_weight_3\")\n  _9 = ops.prepacked.conv2d_clamp_run(input2, prepack_folding__jit_pass_packed_weight_3)\n  input3 = torch.silu_(_9)\n  prepack_folding__jit_pass_packed_weight_4 = getattr(self, \"prepack_folding._jit_pass_packed_weight_4\")\n  _10 = ops.prepacked.conv2d_clamp_run(input3, prepack_folding__jit_pass_packed_weight_4)\n  x0 = torch.feature_dropout(_10, 0.10000000000000001, False)\n  _11 = torch._add_relu(x0, input1)\n  prepack_folding__jit_pass_packed_weight_5 = getattr(self, \"prepack_folding._jit_pass_packed_weight_5\")\n  _12 = ops.prepacked.conv2d_clamp_run(_11, prepack_folding__jit_pass_packed_weight_5)\n  _13 = torch.size(_12, 0)\n  _14 = torch.size(_12, 1)\n  c0 = ops.prim.NumToTensor(_14)\n  _15 = torch.size(_12, 2)\n  h0 = ops.prim.NumToTensor(_15)\n  _16 = torch.size(_12, 3)\n  _17 = int(torch.mul(c0, CONSTANTS.c0))\n  _18 = int(torch.floor_divide(h0, CONSTANTS.c0))\n  input4 = torch.view(_12, [_13, _17, _18, _16])\n  x1 = torch.batch_norm(input4, CONSTANTS.c5, CONSTANTS.c6, CONSTANTS.c7, CONSTANTS.c8, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input5 = torch.view(x1, [_13, _14, _15, _16])\n  input6 = torch.adaptive_avg_pool2d(input5, [1, 201])\n  prepack_folding__jit_pass_packed_weight_6 = getattr(self, \"prepack_folding._jit_pass_packed_weight_6\")\n  _19 = ops.prepacked.conv2d_clamp_run(input6, prepack_folding__jit_pass_packed_weight_6)\n  input7 = torch.silu_(_19)\n  prepack_folding__jit_pass_packed_weight_7 = getattr(self, \"prepack_folding._jit_pass_packed_weight_7\")\n  _20 = ops.prepacked.conv2d_clamp_run(input7, prepack_folding__jit_pass_packed_weight_7)\n  x2 = torch.feature_dropout(_20, 0.10000000000000001, False)\n  x3 = torch.add(x2, input5)\n  _21 = torch._add_relu(x3, _11)\n  prepack_folding__jit_pass_packed_weight_8 = getattr(self, \"prepack_folding._jit_pass_packed_weight_8\")\n  _22 = ops.prepacked.conv2d_clamp_run(_21, prepack_folding__jit_pass_packed_weight_8)\n  prepack_folding__jit_pass_packed_weight_9 = getattr(self, \"prepack_folding._jit_pass_packed_weight_9\")\n  _23 = ops.prepacked.conv2d_clamp_run(_22, prepack_folding__jit_pass_packed_weight_9)\n  _24 = torch.size(_23, 0)\n  _25 = torch.size(_23, 1)\n  c1 = ops.prim.NumToTensor(_25)\n  _26 = torch.size(_23, 2)\n  h1 = ops.prim.NumToTensor(_26)\n  _27 = torch.size(_23, 3)\n  _28 = int(torch.mul(c1, CONSTANTS.c0))\n  _29 = int(torch.floor_divide(h1, CONSTANTS.c0))\n  input8 = torch.view(_23, [_24, _28, _29, _27])\n  x4 = torch.batch_norm(input8, CONSTANTS.c9, CONSTANTS.c10, CONSTANTS.c11, CONSTANTS.c12, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input9 = torch.view(x4, [_24, _25, _26, _27])\n  input10 = torch.adaptive_avg_pool2d(input9, [1, 201])\n  prepack_folding__jit_pass_packed_weight_10 = getattr(self, \"prepack_folding._jit_pass_packed_weight_10\")\n  _30 = ops.prepacked.conv2d_clamp_run(input10, prepack_folding__jit_pass_packed_weight_10)\n  input11 = torch.silu_(_30)\n  prepack_folding__jit_pass_packed_weight_11 = getattr(self, \"prepack_folding._jit_pass_packed_weight_11\")\n  _31 = ops.prepacked.conv2d_clamp_run(input11, prepack_folding__jit_pass_packed_weight_11)\n  x5 = torch.feature_dropout(_31, 0.10000000000000001, False)\n  _32 = torch._add_relu(x5, input9)\n  prepack_folding__jit_pass_packed_weight_12 = getattr(self, \"prepack_folding._jit_pass_packed_weight_12\")\n  _33 = ops.prepacked.conv2d_clamp_run(_32, prepack_folding__jit_pass_packed_weight_12)\n  _34 = torch.size(_33, 0)\n  _35 = torch.size(_33, 1)\n  c2 = ops.prim.NumToTensor(_35)\n  _36 = torch.size(_33, 2)\n  h2 = ops.prim.NumToTensor(_36)\n  _37 = torch.size(_33, 3)\n  _38 = int(torch.mul(c2, CONSTANTS.c0))\n  _39 = int(torch.floor_divide(h2, CONSTANTS.c0))\n  input12 = torch.view(_33, [_34, _38, _39, _37])\n  x6 = torch.batch_norm(input12, CONSTANTS.c13, CONSTANTS.c14, CONSTANTS.c15, CONSTANTS.c16, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input13 = torch.view(x6, [_34, _35, _36, _37])\n  input14 = torch.adaptive_avg_pool2d(input13, [1, 201])\n  prepack_folding__jit_pass_packed_weight_13 = getattr(self, \"prepack_folding._jit_pass_packed_weight_13\")\n  _40 = ops.prepacked.conv2d_clamp_run(input14, prepack_folding__jit_pass_packed_weight_13)\n  input15 = torch.silu_(_40)\n  prepack_folding__jit_pass_packed_weight_14 = getattr(self, \"prepack_folding._jit_pass_packed_weight_14\")\n  _41 = ops.prepacked.conv2d_clamp_run(input15, prepack_folding__jit_pass_packed_weight_14)\n  x7 = torch.feature_dropout(_41, 0.10000000000000001, False)\n  x8 = torch.add(x7, input13)\n  _42 = torch._add_relu(x8, _32)\n  prepack_folding__jit_pass_packed_weight_15 = getattr(self, \"prepack_folding._jit_pass_packed_weight_15\")\n  _43 = ops.prepacked.conv2d_clamp_run(_42, prepack_folding__jit_pass_packed_weight_15)\n  prepack_folding__jit_pass_packed_weight_16 = getattr(self, \"prepack_folding._jit_pass_packed_weight_16\")\n  _44 = ops.prepacked.conv2d_clamp_run(_43, prepack_folding__jit_pass_packed_weight_16)\n  _45 = torch.size(_44, 0)\n  _46 = torch.size(_44, 1)\n  c3 = ops.prim.NumToTensor(_46)\n  _47 = torch.size(_44, 2)\n  h3 = ops.prim.NumToTensor(_47)\n  _48 = torch.size(_44, 3)\n  _49 = int(torch.mul(c3, CONSTANTS.c0))\n  _50 = int(torch.floor_divide(h3, CONSTANTS.c0))\n  input16 = torch.view(_44, [_45, _49, _50, _48])\n  x9 = torch.batch_norm(input16, CONSTANTS.c17, CONSTANTS.c18, CONSTANTS.c19, CONSTANTS.c20, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input17 = torch.view(x9, [_45, _46, _47, _48])\n  input18 = torch.adaptive_avg_pool2d(input17, [1, 201])\n  prepack_folding__jit_pass_packed_weight_17 = getattr(self, \"prepack_folding._jit_pass_packed_weight_17\")\n  _51 = ops.prepacked.conv2d_clamp_run(input18, prepack_folding__jit_pass_packed_weight_17)\n  input19 = torch.silu_(_51)\n  prepack_folding__jit_pass_packed_weight_18 = getattr(self, \"prepack_folding._jit_pass_packed_weight_18\")\n  _52 = ops.prepacked.conv2d_clamp_run(input19, prepack_folding__jit_pass_packed_weight_18)\n  x10 = torch.feature_dropout(_52, 0.10000000000000001, False)\n  _53 = torch._add_relu(x10, input17)\n  prepack_folding__jit_pass_packed_weight_19 = getattr(self, \"prepack_folding._jit_pass_packed_weight_19\")\n  _54 = ops.prepacked.conv2d_clamp_run(_53, prepack_folding__jit_pass_packed_weight_19)\n  _55 = torch.size(_54, 0)\n  _56 = torch.size(_54, 1)\n  c4 = ops.prim.NumToTensor(_56)\n  _57 = torch.size(_54, 2)\n  h4 = ops.prim.NumToTensor(_57)\n  _58 = torch.size(_54, 3)\n  _59 = int(torch.mul(c4, CONSTANTS.c0))\n  _60 = int(torch.floor_divide(h4, CONSTANTS.c0))\n  input20 = torch.view(_54, [_55, _59, _60, _58])\n  x11 = torch.batch_norm(input20, CONSTANTS.c21, CONSTANTS.c22, CONSTANTS.c23, CONSTANTS.c24, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input21 = torch.view(x11, [_55, _56, _57, _58])\n  input22 = torch.adaptive_avg_pool2d(input21, [1, 201])\n  prepack_folding__jit_pass_packed_weight_20 = getattr(self, \"prepack_folding._jit_pass_packed_weight_20\")\n  _61 = ops.prepacked.conv2d_clamp_run(input22, prepack_folding__jit_pass_packed_weight_20)\n  input23 = torch.silu_(_61)\n  prepack_folding__jit_pass_packed_weight_21 = getattr(self, \"prepack_folding._jit_pass_packed_weight_21\")\n  _62 = ops.prepacked.conv2d_clamp_run(input23, prepack_folding__jit_pass_packed_weight_21)\n  x12 = torch.feature_dropout(_62, 0.10000000000000001, False)\n  x13 = torch.add(x12, input21)\n  _63 = torch._add_relu(x13, _53)\n  prepack_folding__jit_pass_packed_weight_22 = getattr(self, \"prepack_folding._jit_pass_packed_weight_22\")\n  _64 = ops.prepacked.conv2d_clamp_run(_63, prepack_folding__jit_pass_packed_weight_22)\n  _65 = torch.size(_64, 0)\n  _66 = torch.size(_64, 1)\n  c5 = ops.prim.NumToTensor(_66)\n  _67 = torch.size(_64, 2)\n  h5 = ops.prim.NumToTensor(_67)\n  _68 = torch.size(_64, 3)\n  _69 = int(torch.mul(c5, CONSTANTS.c0))\n  _70 = int(torch.floor_divide(h5, CONSTANTS.c0))\n  input24 = torch.view(_64, [_65, _69, _70, _68])\n  x14 = torch.batch_norm(input24, CONSTANTS.c25, CONSTANTS.c26, CONSTANTS.c27, CONSTANTS.c28, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input25 = torch.view(x14, [_65, _66, _67, _68])\n  input26 = torch.adaptive_avg_pool2d(input25, [1, 201])\n  prepack_folding__jit_pass_packed_weight_23 = getattr(self, \"prepack_folding._jit_pass_packed_weight_23\")\n  _71 = ops.prepacked.conv2d_clamp_run(input26, prepack_folding__jit_pass_packed_weight_23)\n  input27 = torch.silu_(_71)\n  prepack_folding__jit_pass_packed_weight_24 = getattr(self, \"prepack_folding._jit_pass_packed_weight_24\")\n  _72 = ops.prepacked.conv2d_clamp_run(input27, prepack_folding__jit_pass_packed_weight_24)\n  x15 = torch.feature_dropout(_72, 0.10000000000000001, False)\n  x16 = torch.add(x15, input25)\n  _73 = torch._add_relu(x16, _63)\n  prepack_folding__jit_pass_packed_weight_25 = getattr(self, \"prepack_folding._jit_pass_packed_weight_25\")\n  _74 = ops.prepacked.conv2d_clamp_run(_73, prepack_folding__jit_pass_packed_weight_25)\n  _75 = torch.size(_74, 0)\n  _76 = torch.size(_74, 1)\n  c6 = ops.prim.NumToTensor(_76)\n  _77 = torch.size(_74, 2)\n  h6 = ops.prim.NumToTensor(_77)\n  _78 = torch.size(_74, 3)\n  _79 = int(torch.mul(c6, CONSTANTS.c0))\n  _80 = int(torch.floor_divide(h6, CONSTANTS.c0))\n  input28 = torch.view(_74, [_75, _79, _80, _78])\n  x17 = torch.batch_norm(input28, CONSTANTS.c29, CONSTANTS.c30, CONSTANTS.c31, CONSTANTS.c32, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input29 = torch.view(x17, [_75, _76, _77, _78])\n  input30 = torch.adaptive_avg_pool2d(input29, [1, 201])\n  prepack_folding__jit_pass_packed_weight_26 = getattr(self, \"prepack_folding._jit_pass_packed_weight_26\")\n  _81 = ops.prepacked.conv2d_clamp_run(input30, prepack_folding__jit_pass_packed_weight_26)\n  input31 = torch.silu_(_81)\n  prepack_folding__jit_pass_packed_weight_27 = getattr(self, \"prepack_folding._jit_pass_packed_weight_27\")\n  _82 = ops.prepacked.conv2d_clamp_run(input31, prepack_folding__jit_pass_packed_weight_27)\n  x18 = torch.feature_dropout(_82, 0.10000000000000001, False)\n  x19 = torch.add(x18, input29)\n  _83 = torch._add_relu(x19, _73)\n  prepack_folding__jit_pass_packed_weight_28 = getattr(self, \"prepack_folding._jit_pass_packed_weight_28\")\n  _84 = ops.prepacked.conv2d_clamp_run(_83, prepack_folding__jit_pass_packed_weight_28)\n  prepack_folding__jit_pass_packed_weight_29 = getattr(self, \"prepack_folding._jit_pass_packed_weight_29\")\n  _85 = ops.prepacked.conv2d_clamp_run(_84, prepack_folding__jit_pass_packed_weight_29)\n  _86 = torch.size(_85, 0)\n  _87 = torch.size(_85, 1)\n  c7 = ops.prim.NumToTensor(_87)\n  _88 = torch.size(_85, 2)\n  h7 = ops.prim.NumToTensor(_88)\n  _89 = torch.size(_85, 3)\n  _90 = int(torch.mul(c7, CONSTANTS.c0))\n  _91 = int(torch.floor_divide(h7, CONSTANTS.c0))\n  input32 = torch.view(_85, [_86, _90, _91, _89])\n  x20 = torch.batch_norm(input32, CONSTANTS.c33, CONSTANTS.c34, CONSTANTS.c35, CONSTANTS.c36, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input33 = torch.view(x20, [_86, _87, _88, _89])\n  input34 = torch.adaptive_avg_pool2d(input33, [1, 201])\n  prepack_folding__jit_pass_packed_weight_30 = getattr(self, \"prepack_folding._jit_pass_packed_weight_30\")\n  _92 = ops.prepacked.conv2d_clamp_run(input34, prepack_folding__jit_pass_packed_weight_30)\n  input35 = torch.silu_(_92)\n  prepack_folding__jit_pass_packed_weight_31 = getattr(self, \"prepack_folding._jit_pass_packed_weight_31\")\n  _93 = ops.prepacked.conv2d_clamp_run(input35, prepack_folding__jit_pass_packed_weight_31)\n  x21 = torch.feature_dropout(_93, 0.10000000000000001, False)\n  _94 = torch._add_relu(x21, input33)\n  prepack_folding__jit_pass_packed_weight_32 = getattr(self, \"prepack_folding._jit_pass_packed_weight_32\")\n  _95 = ops.prepacked.conv2d_clamp_run(_94, prepack_folding__jit_pass_packed_weight_32)\n  _96 = torch.size(_95, 0)\n  _97 = torch.size(_95, 1)\n  c8 = ops.prim.NumToTensor(_97)\n  _98 = torch.size(_95, 2)\n  h8 = ops.prim.NumToTensor(_98)\n  _99 = torch.size(_95, 3)\n  _100 = int(torch.mul(c8, CONSTANTS.c0))\n  _101 = int(torch.floor_divide(h8, CONSTANTS.c0))\n  input36 = torch.view(_95, [_96, _100, _101, _99])\n  x22 = torch.batch_norm(input36, CONSTANTS.c37, CONSTANTS.c38, CONSTANTS.c39, CONSTANTS.c40, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input37 = torch.view(x22, [_96, _97, _98, _99])\n  input38 = torch.adaptive_avg_pool2d(input37, [1, 201])\n  prepack_folding__jit_pass_packed_weight_33 = getattr(self, \"prepack_folding._jit_pass_packed_weight_33\")\n  _102 = ops.prepacked.conv2d_clamp_run(input38, prepack_folding__jit_pass_packed_weight_33)\n  input39 = torch.silu_(_102)\n  prepack_folding__jit_pass_packed_weight_34 = getattr(self, \"prepack_folding._jit_pass_packed_weight_34\")\n  _103 = ops.prepacked.conv2d_clamp_run(input39, prepack_folding__jit_pass_packed_weight_34)\n  x23 = torch.feature_dropout(_103, 0.10000000000000001, False)\n  x24 = torch.add(x23, input37)\n  _104 = torch._add_relu(x24, _94)\n  prepack_folding__jit_pass_packed_weight_35 = getattr(self, \"prepack_folding._jit_pass_packed_weight_35\")\n  _105 = ops.prepacked.conv2d_clamp_run(_104, prepack_folding__jit_pass_packed_weight_35)\n  _106 = torch.size(_105, 0)\n  _107 = torch.size(_105, 1)\n  c9 = ops.prim.NumToTensor(_107)\n  _108 = torch.size(_105, 2)\n  h9 = ops.prim.NumToTensor(_108)\n  _109 = torch.size(_105, 3)\n  _110 = int(torch.mul(c9, CONSTANTS.c0))\n  _111 = int(torch.floor_divide(h9, CONSTANTS.c0))\n  input40 = torch.view(_105, [_106, _110, _111, _109])\n  x25 = torch.batch_norm(input40, CONSTANTS.c41, CONSTANTS.c42, CONSTANTS.c43, CONSTANTS.c44, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input41 = torch.view(x25, [_106, _107, _108, _109])\n  input42 = torch.adaptive_avg_pool2d(input41, [1, 201])\n  prepack_folding__jit_pass_packed_weight_36 = getattr(self, \"prepack_folding._jit_pass_packed_weight_36\")\n  _112 = ops.prepacked.conv2d_clamp_run(input42, prepack_folding__jit_pass_packed_weight_36)\n  input43 = torch.silu_(_112)\n  prepack_folding__jit_pass_packed_weight_37 = getattr(self, \"prepack_folding._jit_pass_packed_weight_37\")\n  _113 = ops.prepacked.conv2d_clamp_run(input43, prepack_folding__jit_pass_packed_weight_37)\n  x26 = torch.feature_dropout(_113, 0.10000000000000001, False)\n  x27 = torch.add(x26, input41)\n  _114 = torch._add_relu(x27, _104)\n  prepack_folding__jit_pass_packed_weight_38 = getattr(self, \"prepack_folding._jit_pass_packed_weight_38\")\n  _115 = ops.prepacked.conv2d_clamp_run(_114, prepack_folding__jit_pass_packed_weight_38)\n  _116 = torch.size(_115, 0)\n  _117 = torch.size(_115, 1)\n  c10 = ops.prim.NumToTensor(_117)\n  _118 = torch.size(_115, 2)\n  h10 = ops.prim.NumToTensor(_118)\n  _119 = torch.size(_115, 3)\n  _120 = int(torch.mul(c10, CONSTANTS.c0))\n  _121 = int(torch.floor_divide(h10, CONSTANTS.c0))\n  input44 = torch.view(_115, [_116, _120, _121, _119])\n  x28 = torch.batch_norm(input44, CONSTANTS.c45, CONSTANTS.c46, CONSTANTS.c47, CONSTANTS.c48, False, 0.10000000000000001, 1.0000000000000001e-05, True)\n  input45 = torch.view(x28, [_116, _117, _118, _119])\n  input46 = torch.adaptive_avg_pool2d(input45, [1, 201])\n  prepack_folding__jit_pass_packed_weight_39 = getattr(self, \"prepack_folding._jit_pass_packed_weight_39\")\n  _122 = ops.prepacked.conv2d_clamp_run(input46, prepack_folding__jit_pass_packed_weight_39)\n  input47 = torch.silu_(_122)\n  prepack_folding__jit_pass_packed_weight_40 = getattr(self, \"prepack_folding._jit_pass_packed_weight_40\")\n  _123 = ops.prepacked.conv2d_clamp_run(input47, prepack_folding__jit_pass_packed_weight_40)\n  x29 = torch.feature_dropout(_123, 0.10000000000000001, False)\n  x30 = torch.add(x29, input45)\n  _124 = torch._add_relu(x30, _114)\n  prepack_folding__jit_pass_packed_weight_41 = getattr(self, \"prepack_folding._jit_pass_packed_weight_41\")\n  _125 = ops.prepacked.conv2d_clamp_run(_124, prepack_folding__jit_pass_packed_weight_41)\n  prepack_folding__jit_pass_packed_weight_42 = getattr(self, \"prepack_folding._jit_pass_packed_weight_42\")\n  _126 = ops.prepacked.conv2d_clamp_run(_125, prepack_folding__jit_pass_packed_weight_42)\n  input48 = torch.adaptive_avg_pool2d(_126, [1, 1])\n  prepack_folding__jit_pass_packed_weight_43 = getattr(self, \"prepack_folding._jit_pass_packed_weight_43\")\n  _127 = ops.prepacked.conv2d_clamp_run(input48, prepack_folding__jit_pass_packed_weight_43)\n  _128 = torch.view(_127, [-1, torch.size(_127, 1)])\n  return _128\n"
    },
    "layer_details": {}
}